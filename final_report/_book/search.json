[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "재실감지 프로젝트 보고서",
    "section": "",
    "text": "AQARA 재실감지 프로젝트"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "3  References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "1  Raw Data Analysis",
    "section": "",
    "text": "1.0.1 Exploratory Data Analysis\n\naqara %&gt;% str()\n\nClasses 'data.table' and 'data.frame':  3900 obs. of  8 variables:\n $ timestamp  : POSIXct, format: \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" ...\n $ co2        : num  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  2297 2297 2297 2297 2297 ...\n $ humidity   : num  4271 4271 4271 4271 4271 ...\n $ door       : num  54613010 54673025 54733026 54793030 54853005 ...\n $ motion     : num  22018948 22078965 22138954 22198955 22258939 ...\n $ fp2        : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ occupancy  : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\naqara %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n3900\n\n\nNumber of columns\n8\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n5\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nfp2\n0\n1\nFALSE\n2\ndet: 2718, non: 1182\n\n\noccupancy\n0\n1\nFALSE\n2\ndet: 2199, non: 1701\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nco2\n0\n1\n882.93\n217.76\n443\n703.0\n864.0\n1045\n1624\n▅▇▆▂▁\n\n\ntemperature\n0\n1\n2471.75\n145.41\n2108\n2433.0\n2518.0\n2570\n2667\n▂▂▃▇▇\n\n\nhumidity\n0\n1\n4999.89\n361.70\n4271\n4716.0\n4935.0\n5348\n5537\n▂▆▅▃▇\n\n\ndoor\n0\n1\n4935426.47\n21467539.89\n107\n378347.2\n1064642.5\n2147328\n163814931\n▇▁▁▁▁\n\n\nmotion\n0\n1\n1267060.27\n3239425.31\n897\n54805.5\n204646.5\n1147671\n25618955\n▇▁▁▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ntimestamp\n0\n1\n2023-05-25 08:00:00\n2023-06-21 16:59:00\n2023-06-12 16:29:30\n3900\n\n\n\n\n\n\naqara &lt;- aqara %&gt;% \n  mutate(year = year(timestamp),\n         month = month(timestamp),\n         day = day(timestamp),\n         weekday = weekdays(timestamp),\n         hour = hour(timestamp),\n         minute = minute(timestamp),\n         temperature = temperature/100,\n         humidity = humidity/100) \naqara %&gt;% \n  head()\n\n             timestamp co2 temperature humidity     door   motion           fp2\n1: 2023-05-25 08:00:00 560       22.97    42.71 54613010 22018948 non_detection\n2: 2023-05-25 08:01:00 590       22.97    42.71 54673025 22078965 non_detection\n3: 2023-05-25 08:02:00 590       22.97    42.71 54733026 22138954 non_detection\n4: 2023-05-25 08:03:00 590       22.97    42.71 54793030 22198955 non_detection\n5: 2023-05-25 08:04:00 590       22.97    42.71 54853005 22258939 non_detection\n6: 2023-05-25 08:05:00 590       22.97    42.71 54913014 22318954 non_detection\n       occupancy year month day  weekday hour minute\n1: non_detection 2023     5  25 Thursday    8      0\n2: non_detection 2023     5  25 Thursday    8      1\n3: non_detection 2023     5  25 Thursday    8      2\n4: non_detection 2023     5  25 Thursday    8      3\n5: non_detection 2023     5  25 Thursday    8      4\n6: non_detection 2023     5  25 Thursday    8      5\n\n\n\naqara %&gt;% \n  select_if(is.numeric) %&gt;%\n  gather() %&gt;% \n  ggplot(mapping=aes(x=value,fill=key)) +\n  facet_wrap(~key,scale='free')+\n  geom_boxplot() +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\naqara %&gt;% \n  select_if(is.numeric) %&gt;% \n  pivot_longer(cols=everything()) %&gt;% \n  ggplot(mapping=aes(x=value,fill=name)) +\n  geom_histogram() +\n  facet_wrap(~name,scale='free') +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\nplot_boxplot(aqara,by = \"occupancy\",ncol=3)\n\n\n\n\n\nplot_boxplot(aqara,by = \"fp2\",ncol=3)\n\n\n\n\n\nplot_bar(data=aqara %&gt;% select(-timestamp),by=\"occupancy\",ncol=2)\n\n\n\n\n\naqara &lt;- aqara %&gt;% \n  filter(!weekday=='Sunday') \n\n\nplot_boxplot(aqara,by = \"weekday\",ncol=3)\n\n\n\n\n\naqara %&gt;% \n  ggpairs(aes(fill=occupancy))\n\n\n\n\n\nwrite.csv(aqara,\"eda.csv\")"
  },
  {
    "objectID": "statistics.html",
    "href": "statistics.html",
    "title": "2  statistics",
    "section": "",
    "text": "3 통계 검정\n\nst_aqara &lt;- read.csv(\"eda.csv\")\nst_aqara %&gt;% glimpse()\n\nRows: 3,420\nColumns: 15\n$ X           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ timestamp   &lt;chr&gt; \"2023-05-25 08:00:00\", \"2023-05-25 08:01:00\", \"2023-05-25 …\n$ co2         &lt;int&gt; 560, 590, 590, 590, 590, 590, 625, 625, 625, 625, 625, 660…\n$ temperature &lt;dbl&gt; 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22…\n$ humidity    &lt;dbl&gt; 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42…\n$ door        &lt;int&gt; 54613010, 54673025, 54733026, 54793030, 54853005, 54913014…\n$ motion      &lt;int&gt; 22018948, 22078965, 22138954, 22198955, 22258939, 22318954…\n$ fp2         &lt;chr&gt; \"non_detection\", \"non_detection\", \"non_detection\", \"non_de…\n$ occupancy   &lt;chr&gt; \"non_detection\", \"non_detection\", \"non_detection\", \"non_de…\n$ year        &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023…\n$ month       &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ day         &lt;int&gt; 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25…\n$ weekday     &lt;chr&gt; \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\"…\n$ hour        &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…\n$ minute      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n\n\n\nst_aqara &lt;- st_aqara %&gt;% \n  mutate(timestamp = as.POSIXct(timestamp)) %&gt;% \n  mutate_if(is.character, as.factor)\nst_aqara %&gt;% \n  str()\n\n'data.frame':   3420 obs. of  15 variables:\n $ X          : int  1 2 3 4 5 6 7 8 9 10 ...\n $ timestamp  : POSIXct, format: \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" ...\n $ co2        : int  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  23 23 23 23 23 ...\n $ humidity   : num  42.7 42.7 42.7 42.7 42.7 ...\n $ door       : int  54613010 54673025 54733026 54793030 54853005 54913014 54973018 55033025 55093088 55152999 ...\n $ motion     : int  22018948 22078965 22138954 22198955 22258939 22318954 22378947 22438965 22499015 22558943 ...\n $ fp2        : Factor w/ 2 levels \"detection\",\"non_detection\": 2 2 2 2 2 2 2 2 2 2 ...\n $ occupancy  : Factor w/ 2 levels \"detection\",\"non_detection\": 2 2 2 2 2 2 2 2 2 2 ...\n $ year       : int  2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ month      : int  5 5 5 5 5 5 5 5 5 5 ...\n $ day        : int  25 25 25 25 25 25 25 25 25 25 ...\n $ weekday    : Factor w/ 4 levels \"Monday\",\"Thursday\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ hour       : int  8 8 8 8 8 8 8 8 8 8 ...\n $ minute     : int  0 1 2 3 4 5 6 7 8 9 ...\n\n\n\nOccupancy 유무에 따라 CO2 평균값에 차이가 있는지 검정\nNull Hypothesis: occupancy 유무에 따른 CO2평균값의 차이는 없다.\nAlternative Hypothesis: occupancy 유무에 따른 CO2평균값의 차이가 있다.\n\n\nresult &lt;- t.test(co2 ~ occupancy,data=st_aqara)\nresult\n\n\n    Welch Two Sample t-test\n\ndata:  co2 by occupancy\nt = 34.632, df = 3365.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group detection and group non_detection is not equal to 0\n95 percent confidence interval:\n 203.2863 227.6856\nsample estimates:\n    mean in group detection mean in group non_detection \n                   972.0119                    756.5259 \n\n\n\nco2_occupancy &lt;- lm(co2 ~ occupancy,data=st_aqara)\nplot(co2_occupancy)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# residual normality\nshapiro.test(resid(co2_occupancy))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(co2_occupancy)\nW = 0.9803, p-value &lt; 2.2e-16\n\nco2_detection &lt;- st_aqara %&gt;% \n  filter(occupancy==\"detection\") %&gt;% \n  select(co2)\nco2_non_detection &lt;- st_aqara %&gt;% \n  filter(occupancy==\"non_detection\") %&gt;% \n  select(co2)\n# when detected, normality\nshapiro.test(co2_detection$co2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  co2_detection$co2\nW = 0.99224, p-value = 2.415e-08\n\n# when not detected, normality\nshapiro.test(co2_non_detection$co2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  co2_non_detection$co2\nW = 0.93696, p-value &lt; 2.2e-16\n\n\n위의 Shapiro-Wilk 정규성 결과에 따라 정규성을 따르고 있지 않으므로 비모수 검정 시행(Wilcox\n\nresult &lt;- wilcox.test(co2 ~ occupancy,alternative=\"two.sided\",data=st_aqara)\nresult\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  co2 by occupancy\nW = 2347174, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nWilcoxon rank sum test결과 유의확률이 유의수준(0.05)보다 작으므로, 귀무가설을 기각한다. 즉, occupancy유무에 따라 co2의 평균값에 유의한 차이를 보인다.\n\nOccupancy 유무에 따라 Temperature 평균값에 차이가 있는지 검정\nOccupancy 유무에 따라 Humidity 평균값에 차이가 있는지 검정\nfp2와 occupancy 의 독립성 검정"
  },
  {
    "objectID": "statistics.html#통계-검정",
    "href": "statistics.html#통계-검정",
    "title": "2  Statistics",
    "section": "2.1 통계 검정",
    "text": "2.1 통계 검정\n\nst_aqara &lt;- read.csv(\"eda.csv\")\nst_aqara %&gt;% glimpse()\n\nRows: 3,420\nColumns: 15\n$ X           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ timestamp   &lt;chr&gt; \"2023-05-25 08:00:00\", \"2023-05-25 08:01:00\", \"2023-05-25 …\n$ co2         &lt;int&gt; 560, 590, 590, 590, 590, 590, 625, 625, 625, 625, 625, 660…\n$ temperature &lt;dbl&gt; 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22.97, 22…\n$ humidity    &lt;dbl&gt; 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42.71, 42…\n$ door        &lt;int&gt; 54613010, 54673025, 54733026, 54793030, 54853005, 54913014…\n$ motion      &lt;int&gt; 22018948, 22078965, 22138954, 22198955, 22258939, 22318954…\n$ fp2         &lt;chr&gt; \"non_detection\", \"non_detection\", \"non_detection\", \"non_de…\n$ occupancy   &lt;chr&gt; \"non_detection\", \"non_detection\", \"non_detection\", \"non_de…\n$ year        &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023…\n$ month       &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ day         &lt;int&gt; 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25…\n$ weekday     &lt;chr&gt; \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\"…\n$ hour        &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…\n$ minute      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n\n\n\nst_aqara &lt;- st_aqara %&gt;% \n  mutate(timestamp = as.POSIXct(timestamp)) %&gt;% \n  mutate_if(is.character, as.factor)\nst_aqara %&gt;% \n  str()\n\n'data.frame':   3420 obs. of  15 variables:\n $ X          : int  1 2 3 4 5 6 7 8 9 10 ...\n $ timestamp  : POSIXct, format: \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" ...\n $ co2        : int  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  23 23 23 23 23 ...\n $ humidity   : num  42.7 42.7 42.7 42.7 42.7 ...\n $ door       : int  54613010 54673025 54733026 54793030 54853005 54913014 54973018 55033025 55093088 55152999 ...\n $ motion     : int  22018948 22078965 22138954 22198955 22258939 22318954 22378947 22438965 22499015 22558943 ...\n $ fp2        : Factor w/ 2 levels \"detection\",\"non_detection\": 2 2 2 2 2 2 2 2 2 2 ...\n $ occupancy  : Factor w/ 2 levels \"detection\",\"non_detection\": 2 2 2 2 2 2 2 2 2 2 ...\n $ year       : int  2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ month      : int  5 5 5 5 5 5 5 5 5 5 ...\n $ day        : int  25 25 25 25 25 25 25 25 25 25 ...\n $ weekday    : Factor w/ 4 levels \"Monday\",\"Thursday\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ hour       : int  8 8 8 8 8 8 8 8 8 8 ...\n $ minute     : int  0 1 2 3 4 5 6 7 8 9 ...\n\n\n\n2.1.1 Occupancy 유무에 따라 CO2 평균값에 차이가 있는지 검정\nNull Hypothesis: occupancy 유무에 따른 CO2평균값의 차이는 없다.\n\nAlternative Hypothesis: occupancy 유무에 따른 CO2평균값의 차이가 있다.\n\nresult &lt;- t.test(co2 ~ occupancy,data=st_aqara)\nresult\n\n\n    Welch Two Sample t-test\n\ndata:  co2 by occupancy\nt = 34.632, df = 3365.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group detection and group non_detection is not equal to 0\n95 percent confidence interval:\n 203.2863 227.6856\nsample estimates:\n    mean in group detection mean in group non_detection \n                   972.0119                    756.5259 \n\n\n\nco2_occupancy &lt;- lm(co2 ~ occupancy,data=st_aqara)\nplot(co2_occupancy)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# residual normality test\nshapiro.test(resid(co2_occupancy))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(co2_occupancy)\nW = 0.9803, p-value &lt; 2.2e-16\n\nco2_detection &lt;- st_aqara %&gt;% \n  filter(occupancy==\"detection\") %&gt;% \n  select(co2)\nco2_non_detection &lt;- st_aqara %&gt;% \n  filter(occupancy==\"non_detection\") %&gt;% \n  select(co2)\n# when detected, normality test\nshapiro.test(co2_detection$co2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  co2_detection$co2\nW = 0.99224, p-value = 2.415e-08\n\n# when not detected, normality test\nshapiro.test(co2_non_detection$co2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  co2_non_detection$co2\nW = 0.93696, p-value &lt; 2.2e-16\n\n\n위의 Shapiro-Wilk 정규성 결과에 따라 정규성을 따르고 있지 않으므로 비모수 검정 시행(Wilcox 순위합 검정)\n\nresult &lt;- wilcox.test(co2 ~ occupancy,alternative=\"two.sided\",data=st_aqara)\nresult\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  co2 by occupancy\nW = 2347174, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nWilcoxon rank sum test결과 유의확률이 유의수준(0.05)보다 작으므로, 귀무가설을 기각한다. 즉, occupancy유무에 따라 co2의 평균값에 유의한 차이를 보인다.\n\n\n2.1.2 Occupancy 유무에 따라 Temperature 평균값에 차이가 있는지 검정\nNull Hypothesis: occupancy 유무에 따른 Temperature평균값의 차이는 없다.\nAlternative Hypothesis: occupancy 유무에 따른 Temperature평균값의 차이가 있다.\n\n# Normality Test\nwith(st_aqara,shapiro.test(temperature))\n\n\n    Shapiro-Wilk normality test\n\ndata:  temperature\nW = 0.84243, p-value &lt; 2.2e-16\n\n\n위의 Shapiro-Wilk 정규성 검정 결과, 정규성을 따르지 않으므로 Wilcox 순위합 검정을 시행한다.\n\nresult &lt;- wilcox.test(temperature ~ occupancy,alternative=\"two.sided\",data=st_aqara)\nresult\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  temperature by occupancy\nW = 1663951, p-value = 1.518e-13\nalternative hypothesis: true location shift is not equal to 0\n\n\nWilcoxon rank sum test결과 유의확률이 유의수준(0.05)보다 작으므로, 귀무가설을 기각한다. 즉, occupancy유무에 따라 temperature의 평균값에 유의한 차이를 보인다.\n\n\n2.1.3 Occupancy 유무에 따라 Humidity 평균값에 차이가 있는지 검정\nNull Hypothesis: occupancy 유무에 따른 Humidity 평균값의 차이는 없다.\nAlternative Hypothesis: occupancy 유무에 따른 CO2평균값의 차이가 있다.\n\n# Normality Test\nwith(st_aqara,shapiro.test(humidity))\n\n\n    Shapiro-Wilk normality test\n\ndata:  humidity\nW = 0.93167, p-value &lt; 2.2e-16\n\n\n위의 Shapiro-Wilk 정규성 검정 결과, 정규성을 따르지 않으므로 Wilcox 순위합 검정을 시행한다.\n\nresult &lt;- wilcox.test(humidity ~ occupancy,alternative=\"two.sided\",data=st_aqara)\nresult\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  humidity by occupancy\nW = 1716938, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nWilcoxon rank sum test결과 유의확률이 유의수준(0.05)보다 작으므로, 귀무가설을 기각한다. 즉, occupancy유무에 따라 humidity의 평균값에 유의한 차이를 보인다.\n\n\n2.1.4 fp2와 occupancy 의 독립성 검정\nNull Hypothesis: fp2와 occupancy는 독립이다. (두 변수사이에는 아무런 관련이 없다.)\nAlternative Hypothesis: fp2와 occupancy는 독립이 아니다. (두변수 사이에는 관련이 있다.)\n\n2.1.4.1 Contingency Table\n\nct &lt;- with(st_aqara,table(fp2,occupancy))\nct\n\n               occupancy\nfp2             detection non_detection\n  detection          1826           542\n  non_detection        29          1023\n\n\n\n\n2.1.4.2 Chi-square 독립성 검정\n\nresult &lt;- chisq.test(ct)\nresult\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  ct\nX-squared = 1619.5, df = 1, p-value &lt; 2.2e-16\n\n\nChi-square 독립성 검정 결과에 따라 p-value값이 유의수준(0.05)보다 작으므로, 귀무가설을 기각할 수 있다. 즉, fp2와 occupancy와 상호 관련이 있다.\n\n\n2.1.4.3 Chi-square검정의 신뢰성\n\nresult$expected\n\n               occupancy\nfp2             detection non_detection\n  detection     1284.3977     1083.6023\n  non_detection  570.6023      481.3977\n\n\n위 각 셀의 기대값이 모두 5보다 크므로 Chi-square검정은 신뢰할 수 있으므로 위 검정을 받아 드린다."
  },
  {
    "objectID": "eda.html#exploratory-data-analysis",
    "href": "eda.html#exploratory-data-analysis",
    "title": "1  Raw Data Analysis",
    "section": "1.1 Exploratory Data Analysis",
    "text": "1.1 Exploratory Data Analysis\n\naqara %&gt;% str()\n\nClasses 'data.table' and 'data.frame':  3900 obs. of  8 variables:\n $ timestamp  : POSIXct, format: \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" ...\n $ co2        : num  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  2297 2297 2297 2297 2297 ...\n $ humidity   : num  4271 4271 4271 4271 4271 ...\n $ door       : num  54613010 54673025 54733026 54793030 54853005 ...\n $ motion     : num  22018948 22078965 22138954 22198955 22258939 ...\n $ fp2        : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ occupancy  : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\naqara %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n3900\n\n\nNumber of columns\n8\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n5\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nfp2\n0\n1\nFALSE\n2\ndet: 2718, non: 1182\n\n\noccupancy\n0\n1\nFALSE\n2\ndet: 2199, non: 1701\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nco2\n0\n1\n882.93\n217.76\n443\n703.0\n864.0\n1045\n1624\n▅▇▆▂▁\n\n\ntemperature\n0\n1\n2471.75\n145.41\n2108\n2433.0\n2518.0\n2570\n2667\n▂▂▃▇▇\n\n\nhumidity\n0\n1\n4999.89\n361.70\n4271\n4716.0\n4935.0\n5348\n5537\n▂▆▅▃▇\n\n\ndoor\n0\n1\n4935426.47\n21467539.89\n107\n378347.2\n1064642.5\n2147328\n163814931\n▇▁▁▁▁\n\n\nmotion\n0\n1\n1267060.27\n3239425.31\n897\n54805.5\n204646.5\n1147671\n25618955\n▇▁▁▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ntimestamp\n0\n1\n2023-05-25 08:00:00\n2023-06-21 16:59:00\n2023-06-12 16:29:30\n3900\n\n\n\n\n\n\naqara &lt;- aqara %&gt;% \n  mutate(year = year(timestamp),\n         month = month(timestamp),\n         day = day(timestamp),\n         weekday = weekdays(timestamp),\n         hour = hour(timestamp),\n         minute = minute(timestamp),\n         temperature = temperature/100,\n         humidity = humidity/100) \naqara %&gt;% \n  head()\n\n             timestamp co2 temperature humidity     door   motion           fp2\n1: 2023-05-25 08:00:00 560       22.97    42.71 54613010 22018948 non_detection\n2: 2023-05-25 08:01:00 590       22.97    42.71 54673025 22078965 non_detection\n3: 2023-05-25 08:02:00 590       22.97    42.71 54733026 22138954 non_detection\n4: 2023-05-25 08:03:00 590       22.97    42.71 54793030 22198955 non_detection\n5: 2023-05-25 08:04:00 590       22.97    42.71 54853005 22258939 non_detection\n6: 2023-05-25 08:05:00 590       22.97    42.71 54913014 22318954 non_detection\n       occupancy year month day  weekday hour minute\n1: non_detection 2023     5  25 Thursday    8      0\n2: non_detection 2023     5  25 Thursday    8      1\n3: non_detection 2023     5  25 Thursday    8      2\n4: non_detection 2023     5  25 Thursday    8      3\n5: non_detection 2023     5  25 Thursday    8      4\n6: non_detection 2023     5  25 Thursday    8      5\n\n\n\naqara %&gt;% \n  select_if(is.numeric) %&gt;%\n  gather() %&gt;% \n  ggplot(mapping=aes(x=value,fill=key)) +\n  facet_wrap(~key,scale='free')+\n  geom_boxplot() +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\naqara %&gt;% \n  select_if(is.numeric) %&gt;% \n  pivot_longer(cols=everything()) %&gt;% \n  ggplot(mapping=aes(x=value,fill=name)) +\n  geom_histogram() +\n  facet_wrap(~name,scale='free') +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\nplot_boxplot(aqara,by = \"occupancy\",ncol=3)\n\n\n\n\n\nplot_boxplot(aqara,by = \"fp2\",ncol=3)\n\n\n\n\n\nplot_bar(data=aqara %&gt;% select(-timestamp),by=\"occupancy\",ncol=2)\n\n\n\n\n\naqara &lt;- aqara %&gt;% \n  filter(!weekday=='Sunday') \n\n\nplot_boxplot(aqara,by = \"weekday\",ncol=3)\n\n\n\n\n\naqara %&gt;% \n  ggpairs(aes(fill=occupancy))\n\n\n\n\n\naqara %&gt;% \n  ggplot(aes(x=occupancy,y=co2)) +\n  geom_boxplot()\n\n\n\n\n\naqara %&gt;% \n  group_by(occupancy) %&gt;% \n  summarise(min = min(co2),\n            mean = mean(co2),\n            max = max(co2))\n\n# A tibble: 2 × 4\n  occupancy       min  mean   max\n  &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 non_detection   443  757.  1624\n2 detection       465  972.  1586\n\n\n\naqara %&gt;% \n  ggplot(aes(x=weekday,y=co2),col=weekday) +\n  geom_boxplot()\n\n\n\n\n\nwrite.csv(aqara,\"eda.csv\")"
  },
  {
    "objectID": "feature_engineering.html#eda-후-저장된-데이터-로드",
    "href": "feature_engineering.html#eda-후-저장된-데이터-로드",
    "title": "3  Feature Engineering",
    "section": "3.1 EDA 후 저장된 데이터 로드",
    "text": "3.1 EDA 후 저장된 데이터 로드\n\ndat &lt;- read.csv(\"eda.csv\")\ndat %&gt;% str()\n\n'data.frame':   3420 obs. of  15 variables:\n $ X          : int  1 2 3 4 5 6 7 8 9 10 ...\n $ timestamp  : chr  \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" \"2023-05-25 08:02:00\" \"2023-05-25 08:03:00\" ...\n $ co2        : int  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  23 23 23 23 23 ...\n $ humidity   : num  42.7 42.7 42.7 42.7 42.7 ...\n $ door       : int  54613010 54673025 54733026 54793030 54853005 54913014 54973018 55033025 55093088 55152999 ...\n $ motion     : int  22018948 22078965 22138954 22198955 22258939 22318954 22378947 22438965 22499015 22558943 ...\n $ fp2        : chr  \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ occupancy  : chr  \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ year       : int  2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ month      : int  5 5 5 5 5 5 5 5 5 5 ...\n $ day        : int  25 25 25 25 25 25 25 25 25 25 ...\n $ weekday    : chr  \"Thursday\" \"Thursday\" \"Thursday\" \"Thursday\" ...\n $ hour       : int  8 8 8 8 8 8 8 8 8 8 ...\n $ minute     : int  0 1 2 3 4 5 6 7 8 9 ...\n\ndat_m &lt;- dat %&gt;% \n  select(-X) %&gt;% \n  mutate(timestamp= as.POSIXct(timestamp)) %&gt;% \n  mutate_if(is.character, as.factor)\n\ndat_m &lt;- dat %&gt;% \n  select(-c(timestamp,year,month,day,minute))\nsplits &lt;- dat_m %&gt;% nrow()*0.8\ntrain &lt;- dat_m[1:splits,]\ntest &lt;- dat_m[(splits+1):(dat_m %&gt;% nrow()),]\ntrain %&gt;% nrow()\n\n[1] 2736\n\ntest %&gt;% nrow()\n\n[1] 684\n\ndat_m%&gt;% is.na() %&gt;% colSums()\n\n          X         co2 temperature    humidity        door      motion \n          0           0           0           0           0           0 \n        fp2   occupancy     weekday        hour \n          0           0           0           0 \n\nwrite.csv(train,\"train.csv\")\nwrite.csv(test,\"test.csv\")"
  },
  {
    "objectID": "feature_engineering.html#traintest-셋-분리",
    "href": "feature_engineering.html#traintest-셋-분리",
    "title": "3  Feature Engineering",
    "section": "3.3 Train/Test 셋 분리",
    "text": "3.3 Train/Test 셋 분리\n\ndat1 &lt;- dat1 %&gt;% \n  select(-c(timestamp,year,month,day,minute))\nsplits &lt;- dat1 %&gt;% nrow()*0.8\ntrain_1 &lt;- dat1[1:splits,]\ntest_1 &lt;- dat1[(splits+1):(dat1 %&gt;% nrow()),]\ntrain_1 %&gt;% nrow()\n\n[1] 2732\n\ntest_1 %&gt;% nrow()\n\n[1] 683\n\n\n\ndat1 |&gt; is.na() |&gt; colSums()\n\n                          X                         co2 \n                          0                           0 \n                temperature                    humidity \n                          0                           0 \n                       door                      motion \n                          0                           0 \n                        fp2                   occupancy \n                          0                           0 \n                    weekday                        hour \n                          0                           0 \n           discomfort_index             co2_rolling_std \n                          0                           0 \n    temperature_rolling_std        humidity_rolling_std \n                          0                           0 \n         motion_rolling_std            door_rolling_std \n                          0                           0 \nco2_temperature_interaction    co2_humidity_interaction \n                          0                           0 \n                   co2_lag1                    co2_lag2 \n                          0                           0 \n                   co2_lag3                    co2_lag4 \n                          0                           0 \n                   co2_lag5            temperature_lag1 \n                          0                           0 \n           temperature_lag2            temperature_lag3 \n                          0                           0 \n           temperature_lag4            temperature_lag5 \n                          0                           0 \n              humidity_lag1               humidity_lag2 \n                          0                           0 \n              humidity_lag3               humidity_lag4 \n                          0                           0 \n              humidity_lag5 \n                          0 \n\n\n\nwrite.csv(train_1,\"train_1.csv\")\nwrite.csv(test_1,\"test_1.csv\")"
  },
  {
    "objectID": "modeling.html#data-loading",
    "href": "modeling.html#data-loading",
    "title": "4  Modeling",
    "section": "4.1 Data Loading",
    "text": "4.1 Data Loading\n\ntrain &lt;- read.csv(\"train.csv\")\ntest &lt;- read.csv(\"test.csv\")\n\ntrain &lt;- train %&gt;% \n  select(-X,-weekday) %&gt;% \n  mutate_if(is.character,as.factor)\n\ntest &lt;- test %&gt;% \n  select(-X,-weekday) %&gt;% \n  mutate_if(is.character,as.factor)\n\n\nrec &lt;- train %&gt;% \n  recipe(occupancy ~.) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_factor_predictors())"
  },
  {
    "objectID": "modeling.html#baseline-modeling",
    "href": "modeling.html#baseline-modeling",
    "title": "4  Modeling",
    "section": "4.2 Baseline Modeling",
    "text": "4.2 Baseline Modeling\n\n4.2.1 Logistic Regression\n\nlr_mod &lt;- \n  logistic_reg() %&gt;% \n  set_engine('glm')\n\naqara_workflow &lt;- \n  workflow() %&gt;% \n  add_model(lr_mod) %&gt;% \n  add_recipe(rec)\n\naqara_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\nlr_gridsearch &lt;- aqara_workflow %&gt;%\n  fit(data = train)\n\n\nlr_gridsearch %&gt;% \n  pull_workflow_fit() %&gt;% \n  tidy()\n\n# A tibble: 9 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)         -1.17     0.102     -11.5  1.86e-30\n2 X.1                 -0.736    0.102      -7.24 4.60e-13\n3 co2                 -0.667    0.0822     -8.10 5.29e-16\n4 temperature         -0.332    0.0867     -3.83 1.28e- 4\n5 humidity             0.364    0.0874      4.17 3.07e- 5\n6 door                -4.11     0.481      -8.54 1.33e-17\n7 motion               4.40     0.456       9.63 5.78e-22\n8 hour                -0.159    0.0656     -2.42 1.53e- 2\n9 fp2_non_detection    4.97     0.274      18.2  1.04e-73\n\n\n\npred &lt;- predict(lr_gridsearch,test) \npred &lt;- pred$.pred_class\nconfusionMatrix(pred,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           443           129\n  non_detection         2           110\n                                         \n               Accuracy : 0.8085         \n                 95% CI : (0.777, 0.8373)\n    No Information Rate : 0.6506         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.5197         \n                                         \n Mcnemar's Test P-Value : &lt; 2.2e-16      \n                                         \n            Sensitivity : 0.9955         \n            Specificity : 0.4603         \n         Pos Pred Value : 0.7745         \n         Neg Pred Value : 0.9821         \n             Prevalence : 0.6506         \n         Detection Rate : 0.6477         \n   Detection Prevalence : 0.8363         \n      Balanced Accuracy : 0.7279         \n                                         \n       'Positive' Class : detection      \n                                         \n\n\n\npred_prob &lt;- predict(lr_gridsearch,test,type='prob') %&gt;% \n  bind_cols(test %&gt;% select(occupancy))\npred_prob \n\n# A tibble: 684 × 3\n   .pred_detection .pred_non_detection occupancy\n             &lt;dbl&gt;               &lt;dbl&gt; &lt;fct&gt;    \n 1           0.927              0.0727 detection\n 2           0.924              0.0764 detection\n 3           0.919              0.0810 detection\n 4           0.915              0.0847 detection\n 5           0.912              0.0884 detection\n 6           0.955              0.0452 detection\n 7           0.954              0.0464 detection\n 8           0.952              0.0483 detection\n 9           0.950              0.0497 detection\n10           0.948              0.0517 detection\n# ℹ 674 more rows\n\n\n\npred_prob %&gt;% \n  roc_curve(truth=occupancy,.pred_detection) %&gt;% \n  autoplot()\n\n\n\n\n\npred_prob %&gt;% \n  roc_auc(truth = occupancy, .pred_detection)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.899\n\n\n\n\n4.2.2 Random Forest\n\ncontrol &lt;- trainControl(method='cv',\n                        number=5,\n                        classProbs=T,\n                        summaryFunction = twoClassSummary,\n                        savePredictions=\"all\")\n\ntunegrid &lt;- expand.grid(mtry = c(1:5))\n\nrf_gridsearch &lt;- train(rec,train,\n                       method='rf',\n                       trControl = control,\n                       tuneGrid = tunegrid,\n                       metric =\"ROC\")\n\n\npred &lt;- predict(rf_gridsearch,newdata=test)\nconfusionMatrix(pred,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           435            90\n  non_detection        10           149\n                                          \n               Accuracy : 0.8538          \n                 95% CI : (0.8251, 0.8794)\n    No Information Rate : 0.6506          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6514          \n                                          \n Mcnemar's Test P-Value : 2.789e-15       \n                                          \n            Sensitivity : 0.9775          \n            Specificity : 0.6234          \n         Pos Pred Value : 0.8286          \n         Neg Pred Value : 0.9371          \n             Prevalence : 0.6506          \n         Detection Rate : 0.6360          \n   Detection Prevalence : 0.7675          \n      Balanced Accuracy : 0.8005          \n                                          \n       'Positive' Class : detection       \n                                          \n\n\n\n\n4.2.3 Xgboost\n\ncontrol &lt;- trainControl(method='cv',\n                        number=5,\n                        classProbs=T,\n                        summaryFunction = twoClassSummary,\n                        savePredictions=\"all\")\n\n\nxgb_gridsearch &lt;- train(rec,train,\n                       method='xgbTree',\n                       trControl = control,\n                       tuneLength = 3,\n                       metric =\"ROC\",\n                       verbosity = 0)\n\n\npred_xgb &lt;- predict(xgb_gridsearch,newdata=test)\nconfusionMatrix(pred_xgb,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           443           201\n  non_detection         2            38\n                                          \n               Accuracy : 0.7032          \n                 95% CI : (0.6674, 0.7372)\n    No Information Rate : 0.6506          \n    P-Value [Acc &gt; NIR] : 0.001994        \n                                          \n                  Kappa : 0.1914          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9955          \n            Specificity : 0.1590          \n         Pos Pred Value : 0.6879          \n         Neg Pred Value : 0.9500          \n             Prevalence : 0.6506          \n         Detection Rate : 0.6477          \n   Detection Prevalence : 0.9415          \n      Balanced Accuracy : 0.5773          \n                                          \n       'Positive' Class : detection       \n                                          \n\n\n\n\n4.2.4 Support Vector Machine\n\nsvm_gridsearch &lt;- train(rec,train,\n                        method = \"svmPoly\",\n                        trControl = control,\n                        tuneLength = 2,\n                        metric=\"ROC\")\n\n\npred_svm &lt;- predict(svm_gridsearch,newdata=test)\nconfusionMatrix(pred_svm,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           442           182\n  non_detection         3            57\n                                          \n               Accuracy : 0.7295          \n                 95% CI : (0.6946, 0.7625)\n    No Information Rate : 0.6506          \n    P-Value [Acc &gt; NIR] : 6.095e-06       \n                                          \n                  Kappa : 0.2804          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9933          \n            Specificity : 0.2385          \n         Pos Pred Value : 0.7083          \n         Neg Pred Value : 0.9500          \n             Prevalence : 0.6506          \n         Detection Rate : 0.6462          \n   Detection Prevalence : 0.9123          \n      Balanced Accuracy : 0.6159          \n                                          \n       'Positive' Class : detection       \n                                          \n\n\n\n\n4.2.5 Ridge Regression\n\nlambda &lt;- seq(0,1,length=11)\nridge_grid &lt;- expand.grid(alpha=0,lambda=lambda)\nridge_gridsearch &lt;- train(rec,train,\n                       method=\"glmnet\",\n                       trControl = control,\n                       tuneGrid = ridge_grid,\n                       metric = \"ROC\")\n\n\npred_ridge &lt;- predict(ridge_gridsearch,newdata=test)\nconfusionMatrix(pred_ridge,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           441           154\n  non_detection         4            85\n                                          \n               Accuracy : 0.769           \n                 95% CI : (0.7356, 0.8001)\n    No Information Rate : 0.6506          \n    P-Value [Acc &gt; NIR] : 1.276e-11       \n                                          \n                  Kappa : 0.4056          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9910          \n            Specificity : 0.3556          \n         Pos Pred Value : 0.7412          \n         Neg Pred Value : 0.9551          \n             Prevalence : 0.6506          \n         Detection Rate : 0.6447          \n   Detection Prevalence : 0.8699          \n      Balanced Accuracy : 0.6733          \n                                          \n       'Positive' Class : detection       \n                                          \n\n\n\n\n4.2.6 Model Selection Based on Cross-Validation\n\nresamps &lt;- resamples(list(\n                          random_forest = rf_gridsearch,\n                          xgb = xgb_gridsearch,\n                          svm = svm_gridsearch,\n                          ridge = ridge_gridsearch\n                          ))\nsummary(resamps)\n\n\nCall:\nsummary.resamples(object = resamps)\n\nModels: random_forest, xgb, svm, ridge \nNumber of resamples: 5 \n\nROC \n                   Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrandom_forest 0.9851090 0.9876422 0.9901914 0.9897048 0.9906865 0.9948950    0\nxgb           0.9798876 0.9850157 0.9870199 0.9872293 0.9919979 0.9922253    0\nsvm           0.9194433 0.9435033 0.9499547 0.9436320 0.9521879 0.9530711    0\nridge         0.9296646 0.9301753 0.9319417 0.9353642 0.9352067 0.9498327    0\n\nSens \n                   Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrandom_forest 0.9609929 0.9680851 0.9751773 0.9723404 0.9751773 0.9822695    0\nxgb           0.9361702 0.9468085 0.9680851 0.9609929 0.9716312 0.9822695    0\nsvm           0.9751773 0.9787234 0.9787234 0.9815603 0.9858156 0.9893617    0\nridge         0.9361702 0.9432624 0.9503546 0.9517730 0.9645390 0.9645390    0\n\nSpec \n                   Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrandom_forest 0.9172932 0.9396226 0.9433962 0.9442134 0.9509434 0.9698113    0\nxgb           0.9283019 0.9473684 0.9547170 0.9540020 0.9698113 0.9698113    0\nsvm           0.6867925 0.7245283 0.7283019 0.7284835 0.7433962 0.7593985    0\nridge         0.7773585 0.7924528 0.7962264 0.7978806 0.8082707 0.8150943    0\n\n\n\nbwplot(resamps,metric=\"ROC\")\n\n\n\n\nArgument: ROC를 기반으로 판단해 보면, randomForest와 XGB가 가장 우수하나, randomForest가 상대적으로 분산이 작고, 성능도 약간 우수한 편이므로 randomForest를 최종 모델로 선택한 것이 바람직 하다."
  },
  {
    "objectID": "evaluation.html#evaluation---randomforest-모델",
    "href": "evaluation.html#evaluation---randomforest-모델",
    "title": "5  Tuning & Evaluation",
    "section": "5.1 Evaluation - randomForest 모델",
    "text": "5.1 Evaluation - randomForest 모델\nCross Validation 기반하에 채택된 randomForest 모델을 평가해 본다."
  },
  {
    "objectID": "evaluation.html#data-loading",
    "href": "evaluation.html#data-loading",
    "title": "5  Tuning & Evaluation",
    "section": "5.2 Data Loading",
    "text": "5.2 Data Loading\n\ntrain &lt;- read.csv(\"train.csv\")\ntest &lt;- read.csv(\"test.csv\")\n\ntrain &lt;- train %&gt;% \n  select(-X,-weekday) %&gt;% \n  mutate_if(is.character,as.factor)\n\ntest &lt;- test %&gt;% \n  select(-X,-weekday) %&gt;% \n  mutate_if(is.character,as.factor)\n\n\nrec &lt;- train %&gt;% \n  recipe(occupancy ~.) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_factor_predictors())"
  },
  {
    "objectID": "evaluation.html#modeling",
    "href": "evaluation.html#modeling",
    "title": "5  Tuning & Evaluation",
    "section": "5.3 Modeling",
    "text": "5.3 Modeling\n\n5.3.1 Random Forest\n\ncontrol &lt;- trainControl(method='cv',\n                        number=5,\n                        classProbs=T,\n                        summaryFunction = twoClassSummary,\n                        savePredictions=\"all\")\n\ntunegrid &lt;- expand.grid(mtry = c(1:5))\n\nrf_gridsearch &lt;- train(rec,train,\n                       method='rf',\n                       trControl = control,\n                       tuneGrid = tunegrid,\n                       metric =\"ROC\")\n\n\n\n5.3.2 Confusion Matrix\n\npred &lt;- predict(rf_gridsearch,newdata=test)\nconfusionMatrix(pred,test$occupancy)\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      detection non_detection\n  detection           437           103\n  non_detection         8           136\n                                          \n               Accuracy : 0.8377          \n                 95% CI : (0.8079, 0.8646)\n    No Information Rate : 0.6506          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6069          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9820          \n            Specificity : 0.5690          \n         Pos Pred Value : 0.8093          \n         Neg Pred Value : 0.9444          \n             Prevalence : 0.6506          \n         Detection Rate : 0.6389          \n   Detection Prevalence : 0.7895          \n      Balanced Accuracy : 0.7755          \n                                          \n       'Positive' Class : detection       \n                                          \n\n\n\n\n5.3.3 Feature Importance\n\nplot(varImp(rf_gridsearch,scale=F))\n\n\n\n\n\n\n5.3.4 ROC\n\nlibrary(pROC)\npred_prob &lt;- predict(rf_gridsearch,newdata=test,type=\"prob\")[,1]\nroc_result &lt;- roc(response=test$occupancy,\n                  predictor=pred_prob,\n                  levels =rev(levels(test$occupancy)))\n\n\npar(pty=\"s\")\nplot(roc_result,\n     print.thres =\"best\",\n     print.auc = TRUE,\n     legacy.axes = T)"
  },
  {
    "objectID": "eda.html#raw-data-in-a-glance",
    "href": "eda.html#raw-data-in-a-glance",
    "title": "1  Exploratory Data Analysis",
    "section": "1.1 Raw Data in a Glance",
    "text": "1.1 Raw Data in a Glance\n\n1.1.1 데이터 로딩\n\naqara &lt;- fread(\"integrated_0526_0622.csv\")\naqara &lt;- aqara |&gt;  \n  mutate(fp2 = factor(fp2,labels=c(\"non_detection\",\"detection\")),\n         occupancy = factor(occupancy,labels=c(\"non_detection\",\"detection\")),\n         timestamp = timestamp - 15*3600)\n\n\n\n1.1.2 Skimming Data\n\naqara |&gt;  str()\n\nClasses 'data.table' and 'data.frame':  3900 obs. of  8 variables:\n $ timestamp  : POSIXct, format: \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" ...\n $ co2        : num  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature: num  2297 2297 2297 2297 2297 ...\n $ humidity   : num  4271 4271 4271 4271 4271 ...\n $ door       : num  54613010 54673025 54733026 54793030 54853005 ...\n $ motion     : num  22018948 22078965 22138954 22198955 22258939 ...\n $ fp2        : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ occupancy  : Factor w/ 2 levels \"non_detection\",..: 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\naqara |&gt;  skim()\n\n\nData summary\n\n\nName\naqara\n\n\nNumber of rows\n3900\n\n\nNumber of columns\n8\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n5\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nfp2\n0\n1\nFALSE\n2\ndet: 2718, non: 1182\n\n\noccupancy\n0\n1\nFALSE\n2\ndet: 2199, non: 1701\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nco2\n0\n1\n882.93\n217.76\n443\n703.0\n864.0\n1045\n1624\n▅▇▆▂▁\n\n\ntemperature\n0\n1\n2471.75\n145.41\n2108\n2433.0\n2518.0\n2570\n2667\n▂▂▃▇▇\n\n\nhumidity\n0\n1\n4999.89\n361.70\n4271\n4716.0\n4935.0\n5348\n5537\n▂▆▅▃▇\n\n\ndoor\n0\n1\n4935426.47\n21467539.89\n107\n378347.2\n1064642.5\n2147328\n163814931\n▇▁▁▁▁\n\n\nmotion\n0\n1\n1267060.27\n3239425.31\n897\n54805.5\n204646.5\n1147671\n25618955\n▇▁▁▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ntimestamp\n0\n1\n2023-05-25 08:00:00\n2023-06-21 16:59:00\n2023-06-12 16:29:30\n3900\n\n\n\n\n\n\n\n1.1.3 날짜/시간 관련 파생변수 생성\n\naqara &lt;- aqara |&gt;  \n  mutate(year = year(timestamp),\n         month = month(timestamp),\n         day = day(timestamp),\n         weekday = weekdays(timestamp),\n         hour = hour(timestamp),\n         minute = minute(timestamp),\n         temperature = temperature/100,\n         humidity = humidity/100) \naqara |&gt;  \n  head()\n\n             timestamp co2 temperature humidity     door   motion           fp2\n1: 2023-05-25 08:00:00 560       22.97    42.71 54613010 22018948 non_detection\n2: 2023-05-25 08:01:00 590       22.97    42.71 54673025 22078965 non_detection\n3: 2023-05-25 08:02:00 590       22.97    42.71 54733026 22138954 non_detection\n4: 2023-05-25 08:03:00 590       22.97    42.71 54793030 22198955 non_detection\n5: 2023-05-25 08:04:00 590       22.97    42.71 54853005 22258939 non_detection\n6: 2023-05-25 08:05:00 590       22.97    42.71 54913014 22318954 non_detection\n       occupancy year month day  weekday hour minute\n1: non_detection 2023     5  25 Thursday    8      0\n2: non_detection 2023     5  25 Thursday    8      1\n3: non_detection 2023     5  25 Thursday    8      2\n4: non_detection 2023     5  25 Thursday    8      3\n5: non_detection 2023     5  25 Thursday    8      4\n6: non_detection 2023     5  25 Thursday    8      5"
  },
  {
    "objectID": "eda.html#plot-analysis",
    "href": "eda.html#plot-analysis",
    "title": "1  Exploratory Data Analysis",
    "section": "1.2 Plot Analysis",
    "text": "1.2 Plot Analysis\n\n1.2.1 박스플롯\n\naqara |&gt;  \n  select_if(is.numeric) |&gt; \n  gather() |&gt;  \n  ggplot(mapping=aes(x=value,fill=key)) +\n  facet_wrap(~key,scale='free')+\n  geom_boxplot() +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\n\n1.2.2 히스토그램\n\naqara |&gt;  \n  select_if(is.numeric) |&gt;  \n  pivot_longer(cols=everything()) |&gt;  \n  ggplot(mapping=aes(x=value,fill=name)) +\n  geom_histogram() +\n  facet_wrap(~name,scale='free') +\n  theme_minimal() +\n  theme(legend.position='none')\n\n\n\n\n\n\n1.2.3 Occupancy유무에 따른 수치형 변수 박스플롯\n\nplot_boxplot(aqara,by = \"occupancy\",ncol=3)\n\n\n\n\n\n\n1.2.4 fp2 감지 유무에 따른 수치형 변수 박스플롯\n\nplot_boxplot(aqara,by = \"fp2\",ncol=3)\n\n\n\n\n\n\n1.2.5 Occupancy 유무에 따른 범주형 변수 박스플롯\n\nplot_bar(data=aqara |&gt;  select(-timestamp),by=\"occupancy\",ncol=2)\n\n\n\n\n\naqara &lt;- aqara |&gt;  \n  filter(!weekday=='Sunday') \n\n\n\n1.2.6 요일별 수치형 변수 박스플롯 - 현재는 충분한 데이터가 없으므로 의미 없음\n\nplot_boxplot(aqara,by = \"weekday\",ncol=3)\n\n\n\n\n\n\n1.2.7 상관계수\n\naqara |&gt; \n  select(co2,temperature,humidity,door,motion,hour,fp2) |&gt; \n  plot_correlation(cor_args = list(use =\"complete.obs\"))\n\n\n\n\n\n\n1.2.8 Occupancy 유무에 따른 pairs플롯 및 기타\n\naqara |&gt; \n  select(co2,temperature,humidity,door,motion,hour,occupancy) |&gt; \n  ggpairs(aes(fill=occupancy))\n\n\n\n\n\naqara |&gt;  \n  ggplot(aes(x=occupancy,y=co2)) +\n  geom_boxplot()\n\n\n\n\n\naqara %&gt;% \n  ggplot(aes(x=weekday,y=co2),col=weekday) +\n  geom_boxplot()\n\n\n\n\n\naqara |&gt;  \n  group_by(occupancy) |&gt;  \n  summarise(min_co2 = min(co2),\n            mean_co2 = mean(co2),\n            max_co2 = max(co2),\n            min_temperature = min(temperature)*100,\n            mean_temperature = mean(temperature)*100,\n            max_temperature = max(temperature)*100,\n            min_humidity = min(humidity)*100,\n            mean_humidity = mean(humidity)*100,\n            max_humidity = max(humidity)*100)\n\n# A tibble: 2 × 10\n  occupancy     min_co2 mean_co2 max_co2 min_temperature mean_temperature\n  &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1 non_detection     443     757.    1624            2108            2427.\n2 detection         465     972.    1586            2108            2478.\n# ℹ 4 more variables: max_temperature &lt;dbl&gt;, min_humidity &lt;dbl&gt;,\n#   mean_humidity &lt;dbl&gt;, max_humidity &lt;dbl&gt;"
  },
  {
    "objectID": "eda.html#eda-데이터-저장",
    "href": "eda.html#eda-데이터-저장",
    "title": "1  Exploratory Data Analysis",
    "section": "1.3 EDA 데이터 저장",
    "text": "1.3 EDA 데이터 저장\n\nwrite.csv(aqara,\"eda.csv\")"
  },
  {
    "objectID": "demonstration.html#데모-구성",
    "href": "demonstration.html#데모-구성",
    "title": "9  Demonstration",
    "section": "9.1 데모 구성",
    "text": "9.1 데모 구성\nAPI Server (Django), Front-end App with ML\n데모 앱 Github: https://github.com/ariwells2001/hg2024"
  },
  {
    "objectID": "demonstration.html#backend-api-server",
    "href": "demonstration.html#backend-api-server",
    "title": "9  Demonstration",
    "section": "9.2 Backend API Server",
    "text": "9.2 Backend API Server\n\n9.2.1 MariaDB 설치(Mac기준)\n\n### Shell & MySQL COMMANDS\n\n##Mariadb installation\n#brew install mariadb\n#brew services restart mariadb\n\n##restart MAC\n# password 없이 mysql에 로그인\n#sudo mysql -u root\n\n##mysql 로그인 후:\n#use mysql;\n#alter user 'root'@'localhost' identified by 'password'\n\n\n\n9.2.2 Django(models.py)에 정의된 patternTable\n\n#class patternTable(models.Model):\n#    account = models.CharField(max_length=50)\n#    timestamp = models.DateTimeField(auto_now_add=True)\n#    co2 = models.FloatField()\n#    temperature = models.FloatField()\n#    humidity = models.FloatField()\n#    door = models.FloatField()\n#    motion = models.FloatField()\n#    fp2 = models.FloatField()\n#    occupancy = models.FloatField()\n#    user = models.ForeignKey(User,on_delete=models.CASCADE)\n\n#    class Meta:\n#        db_table = 'patternTable'\n#    def __str__(self):\n#        return self.account\n\n\n\n9.2.3 Database에 csv file import 하기\n\n9.2.3.1 Django 서버에서 생성한 테이블에 적합하도록 csv file 변경하기\n\nimport pandas as pd\n\ndf = pd.read_csv(\"integrated_0526_0622.csv\")\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nco2\ntemperature\nhumidity\ndoor\nmotion\nfp2\noccupancy\n\n\n\n\n0\n2023-05-26 08:00:00+09:00\n560.0\n2297.0\n4271.0\n54613010.0\n22018948.0\n0.0\n0.0\n\n\n1\n2023-05-26 08:01:00+09:00\n590.0\n2297.0\n4271.0\n54673025.0\n22078965.0\n0.0\n0.0\n\n\n2\n2023-05-26 08:02:00+09:00\n590.0\n2297.0\n4271.0\n54733026.0\n22138954.0\n0.0\n0.0\n\n\n3\n2023-05-26 08:03:00+09:00\n590.0\n2297.0\n4271.0\n54793030.0\n22198955.0\n0.0\n0.0\n\n\n4\n2023-05-26 08:04:00+09:00\n590.0\n2297.0\n4271.0\n54853005.0\n22258939.0\n0.0\n0.0\n\n\n\n\n\n\n\n기존 데이터프레임 수정\n\ndf.reset_index(inplace=True)\ndf['account'] =\"ariwells2001@gmail.com\"\ndf['id'] = df.iloc[:,0] + 1\ndf['timestamp'] = df['timestamp'].str[:-6]\ndf['user_id'] = 1\ndf = df.loc[:,['id','account','timestamp','co2','temperature','humidity','door','motion','fp2','occupancy','user_id']]\ndf.head(2)\n\n\n\n\n\n\n\n\nid\naccount\ntimestamp\nco2\ntemperature\nhumidity\ndoor\nmotion\nfp2\noccupancy\nuser_id\n\n\n\n\n0\n1\nariwells2001@gmail.com\n2023-05-26 08:00:00\n560.0\n2297.0\n4271.0\n54613010.0\n22018948.0\n0.0\n0.0\n1\n\n\n1\n2\nariwells2001@gmail.com\n2023-05-26 08:01:00\n590.0\n2297.0\n4271.0\n54673025.0\n22078965.0\n0.0\n0.0\n1\n\n\n\n\n\n\n\n\ndf.to_csv(\"iot.csv\",index=False)\ndf.head(2)\n\n\n\n\n\n\n\n\nid\naccount\ntimestamp\nco2\ntemperature\nhumidity\ndoor\nmotion\nfp2\noccupancy\nuser_id\n\n\n\n\n0\n1\nariwells2001@gmail.com\n2023-05-26 08:00:00\n560.0\n2297.0\n4271.0\n54613010.0\n22018948.0\n0.0\n0.0\n1\n\n\n1\n2\nariwells2001@gmail.com\n2023-05-26 08:01:00\n590.0\n2297.0\n4271.0\n54673025.0\n22078965.0\n0.0\n0.0\n1\n\n\n\n\n\n\n\n\n\n\n9.2.4 수정된 csv file Mariadb(mysql)에 import하기\n\n### MYSQL COMMANDS\n\n#mysql에 로그인\n\n##iotuser라는 ID 생성하기\n#create user 'iotuser'@'localhost' identified by 'iot12345';\n#create user 'iotuser'@'%' identified by 'iot12345';\n#grant all privileges on *.* to 'iotuser'@'localhost';\n#grant all privileges on *.* to 'iotuser'@'%';\n#flush privileges;\n\n##Django에서 생성된 테이블(patternTablee)의 user라는 foreign_key를 import시 체크하지 않도록 설정\n#set foreign_key_checks=0\n#load data infile \"iot.csv\" into table patternTable fields terminated by ',' ignore 1 rows;\n#set foreign_key_checks=1  # revert to the original setting\n\n\n\n9.2.5 Django와 MariaDB 연동 테스트\n\nimport requests,json\nimport pandas as pd\n\n\nend_point = 'http://127.0.0.1:8000/backend/random/'\n\ntoken = 'bcffe3ff7ee5e28fae80c9aa23dc33521823d326'\n\nheaders = {\n    'Authorization': 'Token {}'.format(token),\n     'Content-Type': 'application/json;charset=UTF-8',\n     'DN':'100'\n}\nresponse = requests.get(url=end_point,headers=headers)\nprint(response)\ndata = json.loads(response.text)\nstatus = response\ndf = pd.DataFrame(data)\nprint('data is {} and status is {}'.format(data,status))\nprint(df.head())\n\n&lt;Response [200]&gt;\ndata is [{'id': 18, 'account': 'ariwells2001@gmail.com', 'timestamp': '2023-05-26T08:17:00Z', 'co2': 685.0, 'temperature': 2272.0, 'humidity': 4271.0, 'door': 55633008.0, 'motion': 23038951.0, 'fp2': 0.0, 'occupancy': 0.0, 'user': 1}] and status is &lt;Response [200]&gt;\n   id                 account             timestamp    co2  temperature  \\\n0  18  ariwells2001@gmail.com  2023-05-26T08:17:00Z  685.0       2272.0   \n\n   humidity        door      motion  fp2  occupancy  user  \n0    4271.0  55633008.0  23038951.0  0.0        0.0     1  \n\n\n\n\n9.2.6 Frontend App 사용을 위한 DB Data Retrieval\nML학습을 위한 모든 데이터 Retrieval Endpoint:\n’http://127.0.0.1:8000/backend/pattern/’\nOccupancy Detection Simulation을 위한 랜덤데이터 샘플링\n’http://127.0.0.1:8000/backend/random/’\n\n9.2.6.1 전체 데이터 Retrieval (from DB)\n\nimport requests,json\nimport pandas as pd\n\n\nend_point = 'http://127.0.0.1:8000/backend/pattern/'\n\ntoken = 'bcffe3ff7ee5e28fae80c9aa23dc33521823d326'\n\nheaders = {\n    'Authorization': 'Token {}'.format(token),\n     'Content-Type': 'application/json;charset=UTF-8',\n     'DN':'3900'\n}\nresponse = requests.get(url=end_point,headers=headers)\nprint(response)\ndata = json.loads(response.text)\nstatus = response\nprint('status is {}'.format(status))\ndf = pd.DataFrame(data)\ndf['id'] = df['id']-1\ndf = df.sort_values('id',ascending=True)\ndf.set_index('id',drop=True,inplace=True)\ndf.index.name=None\ndf.info()\ndf.head(2)\n\n&lt;Response [200]&gt;\nstatus is &lt;Response [200]&gt;\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 3900 entries, 0 to 3899\nData columns (total 10 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   account      3900 non-null   object \n 1   timestamp    3900 non-null   object \n 2   co2          3900 non-null   float64\n 3   temperature  3900 non-null   float64\n 4   humidity     3900 non-null   float64\n 5   door         3900 non-null   float64\n 6   motion       3900 non-null   float64\n 7   fp2          3900 non-null   float64\n 8   occupancy    3900 non-null   float64\n 9   user         3900 non-null   int64  \ndtypes: float64(7), int64(1), object(2)\nmemory usage: 335.2+ KB\n\n\n\n\n\n\n\n\n\naccount\ntimestamp\nco2\ntemperature\nhumidity\ndoor\nmotion\nfp2\noccupancy\nuser\n\n\n\n\n0\nariwells2001@gmail.com\n2023-05-26T08:00:00Z\n560.0\n2297.0\n4271.0\n54613010.0\n22018948.0\n0.0\n0.0\n1\n\n\n1\nariwells2001@gmail.com\n2023-05-26T08:01:00Z\n590.0\n2297.0\n4271.0\n54673025.0\n22078965.0\n0.0\n0.0\n1\n\n\n\n\n\n\n\n\n\n9.2.6.2 ML 학습에 사용할 수 있도록 데이터 기본 정제\n\ndf['timestamp'] = df['timestamp'].replace(r'[TZ]',r' ',regex=True)\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\ndf[['co2','door','motion','fp2','occupancy']] = df[['co2','door','motion','fp2','occupancy']].astype(int)\ndf[['temperature','humidity']] = df[['temperature','humidity']]/100\ndf = df[['timestamp','co2','temperature','humidity','door','motion','fp2','occupancy']]\ndf.head(5)\n\n\n\n\n\n\n\n\ntimestamp\nco2\ntemperature\nhumidity\ndoor\nmotion\nfp2\noccupancy\n\n\n\n\n0\n2023-05-26 08:00:00\n560\n22.97\n42.71\n54613010\n22018948\n0\n0\n\n\n1\n2023-05-26 08:01:00\n590\n22.97\n42.71\n54673025\n22078965\n0\n0\n\n\n2\n2023-05-26 08:02:00\n590\n22.97\n42.71\n54733026\n22138954\n0\n0\n\n\n3\n2023-05-26 08:03:00\n590\n22.97\n42.71\n54793030\n22198955\n0\n0\n\n\n4\n2023-05-26 08:04:00\n590\n22.97\n42.71\n54853005\n22258939\n0\n0"
  },
  {
    "objectID": "demonstration.html#aqarai-protype",
    "href": "demonstration.html#aqarai-protype",
    "title": "9  Demonstration",
    "section": "9.3 AqarAI Protype",
    "text": "9.3 AqarAI Protype\n\nBackend API Server로 부터 발급 받은 access token을 먼저 입력해야 함\n\n\n9.3.1 기본 EDA 기능\n\n\n\n9.3.2 Backend API 서버로 부터 데이터 retrieval 후 모델링\n\n\n9.3.3 csv file로 부터 모델링\n\n9.3.4 AI 서비스\nBackend API서버로 부터 마지막 레코드 읽어 온 후 occupancy 유무 예측. 현재는 데모 목적으로 random하게 레코드 읽어 옴.\n\n현재 10초 간격으로 서버로 부터 random하게 레코드 읽어옴\nscheduler를 사용해서 구현할 예정이나 현재 문제가 있어 while문 사용\n원하는 모델을 선택하여 예측가능. 모델을 선택하지 않을 경우 현재는 xgboost모델이 사용됨"
  },
  {
    "objectID": "feature_engineering.html#feature-engineering",
    "href": "feature_engineering.html#feature-engineering",
    "title": "3  Feature Engineering",
    "section": "3.2 Feature Engineering",
    "text": "3.2 Feature Engineering\n\n3.2.1 불쾌 지수\n\n# discrete value only with two arguements\n\nf_discomfort &lt;- function(x1,x2) {\n  temperature &lt;- x1\n  humidity &lt;- x2\n  discomfort &lt;- 1.8*temperature - 0.55*(1 - humidity/100)*(1.8*temperature - 26) + 32\n  \n  result &lt;- case_when(\n  discomfort &gt;= 83 ~ as.integer(12),\n  discomfort &gt;= 80 & discomfort &lt; 83 ~ as.integer(10),\n  discomfort &gt;= 75 & discomfort &lt; 80 ~ as.integer(8),\n  discomfort &gt;= 70 & discomfort &lt; 75 ~ as.integer(6),\n  discomfort &gt;= 68 & discomfort &lt; 70 ~ as.integer(4),\n  TRUE ~ as.integer(2)\n  )\n  return (result)\n}\n\n\ndat1 &lt;- dat\ndat1$discomfort_index &lt;- with(dat1,f_discomfort(temperature,humidity))\n#dat&lt;- adply(dat,1,s_discomfort)\n#dat &lt;- adply(dat,1,two_discomfort)\ndat1 |&gt; str()\n\n'data.frame':   3420 obs. of  16 variables:\n $ X               : int  1 2 3 4 5 6 7 8 9 10 ...\n $ timestamp       : chr  \"2023-05-25 08:00:00\" \"2023-05-25 08:01:00\" \"2023-05-25 08:02:00\" \"2023-05-25 08:03:00\" ...\n $ co2             : int  560 590 590 590 590 590 625 625 625 625 ...\n $ temperature     : num  23 23 23 23 23 ...\n $ humidity        : num  42.7 42.7 42.7 42.7 42.7 ...\n $ door            : int  54613010 54673025 54733026 54793030 54853005 54913014 54973018 55033025 55093088 55152999 ...\n $ motion          : int  22018948 22078965 22138954 22198955 22258939 22318954 22378947 22438965 22499015 22558943 ...\n $ fp2             : chr  \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ occupancy       : chr  \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ year            : int  2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ month           : int  5 5 5 5 5 5 5 5 5 5 ...\n $ day             : int  25 25 25 25 25 25 25 25 25 25 ...\n $ weekday         : chr  \"Thursday\" \"Thursday\" \"Thursday\" \"Thursday\" ...\n $ hour            : int  8 8 8 8 8 8 8 8 8 8 ...\n $ minute          : int  0 1 2 3 4 5 6 7 8 9 ...\n $ discomfort_index: int  4 4 4 4 4 4 4 4 4 4 ...\n\n\n\n\n3.2.2 이동표준편차\n\nwindow_size &lt;- 5  # Adjust the window size as per your preference\nrolling_features &lt;- c('co2', 'temperature', 'humidity', 'motion', 'door')\n\n# Group by 'day' and apply rolling sd\ndat1 &lt;- dat1 %&gt;%\n  group_by(day) %&gt;%\n  mutate(across(rolling_features, ~zoo::rollapply(.x, window_size, sd, fill = NA, align = \"right\"), .names = \"{.col}_rolling_std\")) |&gt; \n  ungroup() \n\n\n\n3.2.3 Interaction\n\n# Create interaction features within each day group\ninteraction_features &lt;- list(c('co2', 'temperature'), c('co2', 'humidity'))\ndat1 &lt;- dat1 %&gt;%\n  group_by(day) %&gt;%\n  mutate(across(interaction_features, ~.x[[1]] * (.x[[2]]/10), .names = \"{interaction[[1]]}_{interaction[[2]]}_interaction\")) |&gt; \n  ungroup() \n\n\n\n3.2.4 Lag\n\n# Create lagged features within each day group\nlagged_features &lt;- c('co2', 'temperature', 'humidity')\nlag_steps &lt;- c(1, 2, 3, 4, 5)  # Adjust the lag steps as per your preference\n\ndat1 &lt;- dat1 %&gt;%\n  group_by(day) %&gt;%\n  mutate(across(lagged_features, ~lag(.x, lag_steps))) |&gt; \n  ungroup()\n\n### Final Dataset ###\ndat1 &lt;- dat1[complete.cases(dat1),]\nstr(dat1)\n\ntibble [3,415 × 38] (S3: tbl_df/tbl/data.frame)\n $ X                          : int [1:3415] 6 7 8 9 10 11 12 13 14 15 ...\n $ timestamp                  : chr [1:3415] \"2023-05-25 08:05:00\" \"2023-05-25 08:06:00\" \"2023-05-25 08:07:00\" \"2023-05-25 08:08:00\" ...\n $ co2                        : int [1:3415] 590 625 625 625 625 625 660 660 660 660 ...\n $ temperature                : num [1:3415] 23 23 23 23 23 ...\n $ humidity                   : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ door                       : int [1:3415] 54913014 54973018 55033025 55093088 55152999 55213015 55273015 55333000 55393186 55453016 ...\n $ motion                     : int [1:3415] 22318954 22378947 22438965 22499015 22558943 22618949 22678940 22738938 22799121 22858949 ...\n $ fp2                        : chr [1:3415] \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ occupancy                  : chr [1:3415] \"non_detection\" \"non_detection\" \"non_detection\" \"non_detection\" ...\n $ year                       : int [1:3415] 2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ month                      : int [1:3415] 5 5 5 5 5 5 5 5 5 5 ...\n $ day                        : int [1:3415] 25 25 25 25 25 25 25 25 25 25 ...\n $ weekday                    : chr [1:3415] \"Thursday\" \"Thursday\" \"Thursday\" \"Thursday\" ...\n $ hour                       : int [1:3415] 8 8 8 8 8 8 8 8 8 8 ...\n $ minute                     : int [1:3415] 5 6 7 8 9 10 11 12 13 14 ...\n $ discomfort_index           : int [1:3415] 4 4 4 4 4 4 4 4 4 4 ...\n $ co2_rolling_std            : num [1:3415] 590 597 604 611 618 625 632 639 646 653 ...\n $ temperature_rolling_std    : num [1:3415] 23 23 23 23 23 ...\n $ humidity_rolling_std       : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ motion_rolling_std         : num [1:3415] 22198953 22258950 22318952 22378964 22438965 ...\n $ door_rolling_std           : num [1:3415] 54793020 54853019 54913018 54973030 55033029 ...\n $ co2_temperature_interaction: num [1:3415] 1355 1436 1436 1436 1436 ...\n $ co2_humidity_interaction   : num [1:3415] 2520 2669 2669 2669 2669 ...\n $ co2_lag1                   : int [1:3415] 590 590 625 625 625 625 625 660 660 660 ...\n $ co2_lag2                   : int [1:3415] 590 590 590 625 625 625 625 625 660 660 ...\n $ co2_lag3                   : int [1:3415] 590 590 590 590 625 625 625 625 625 660 ...\n $ co2_lag4                   : int [1:3415] 590 590 590 590 590 625 625 625 625 625 ...\n $ co2_lag5                   : int [1:3415] 560 590 590 590 590 590 625 625 625 625 ...\n $ temperature_lag1           : num [1:3415] 23 23 23 23 23 ...\n $ temperature_lag2           : num [1:3415] 23 23 23 23 23 ...\n $ temperature_lag3           : num [1:3415] 23 23 23 23 23 ...\n $ temperature_lag4           : num [1:3415] 23 23 23 23 23 ...\n $ temperature_lag5           : num [1:3415] 23 23 23 23 23 ...\n $ humidity_lag1              : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ humidity_lag2              : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ humidity_lag3              : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ humidity_lag4              : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ...\n $ humidity_lag5              : num [1:3415] 42.7 42.7 42.7 42.7 42.7 ..."
  },
  {
    "objectID": "modeling_python.html#library-loading",
    "href": "modeling_python.html#library-loading",
    "title": "6  Modeling - Python",
    "section": "6.1 Library Loading",
    "text": "6.1 Library Loading\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport time\nfrom imblearn.over_sampling import SMOTE,RandomOverSampler\nimport joblib\nimport warnings\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,KFold,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler,Normalizer,OneHotEncoder\nfrom sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,classification_report\nfrom sklearn import set_config\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n#from catboost import CatBoostClassifier\nwarnings.filterwarnings(\"ignore\")"
  },
  {
    "objectID": "modeling_python.html#data-loading",
    "href": "modeling_python.html#data-loading",
    "title": "6  Modeling - Python",
    "section": "6.2 Data Loading",
    "text": "6.2 Data Loading\n\ntrain = pd.read_csv(\"train_1.csv\")\ntest = pd.read_csv(\"test_1.csv\")\n\ntrain = train.iloc[:,2:]\ntest = test.iloc[:,2:]\ntrain['fp2'] = np.where(train['fp2']==\"non_detection\",0,1)\ntest['fp2'] = np.where(test['fp2']==\"non_detection\",0,1)\ntrain[\"occupancy\"] = np.where(train[\"occupancy\"] == \"non_detection\",0,1)\ntest[\"occupancy\"]= np.where(test[\"occupancy\"] == \"non_detection\",0,1)\n\ntrain_X = train.drop(['occupancy',\"weekday\"],axis=1)\ntrain_y = train[['occupancy']]\nsmote = SMOTE(random_state=2023,k_neighbors=7)\ntrain_X,train_y = smote.fit_resample(train_X,train_y)\ntest_X = test.drop(['occupancy',\"weekday\"],axis=1)\ntest_y = test[['occupancy']]\n\n\ntrain_X.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2822 entries, 0 to 2821\nData columns (total 30 columns):\n #   Column                       Non-Null Count  Dtype  \n---  ------                       --------------  -----  \n 0   co2                          2822 non-null   int64  \n 1   temperature                  2822 non-null   float64\n 2   humidity                     2822 non-null   float64\n 3   door                         2822 non-null   int64  \n 4   motion                       2822 non-null   int64  \n 5   fp2                          2822 non-null   int64  \n 6   hour                         2822 non-null   int64  \n 7   discomfort_index             2822 non-null   int64  \n 8   co2_rolling_std              2822 non-null   float64\n 9   temperature_rolling_std      2822 non-null   float64\n 10  humidity_rolling_std         2822 non-null   float64\n 11  motion_rolling_std           2822 non-null   float64\n 12  door_rolling_std             2822 non-null   float64\n 13  co2_temperature_interaction  2822 non-null   float64\n 14  co2_humidity_interaction     2822 non-null   float64\n 15  co2_lag1                     2822 non-null   int64  \n 16  co2_lag2                     2822 non-null   int64  \n 17  co2_lag3                     2822 non-null   int64  \n 18  co2_lag4                     2822 non-null   int64  \n 19  co2_lag5                     2822 non-null   int64  \n 20  temperature_lag1             2822 non-null   float64\n 21  temperature_lag2             2822 non-null   float64\n 22  temperature_lag3             2822 non-null   float64\n 23  temperature_lag4             2822 non-null   float64\n 24  temperature_lag5             2822 non-null   float64\n 25  humidity_lag1                2822 non-null   float64\n 26  humidity_lag2                2822 non-null   float64\n 27  humidity_lag3                2822 non-null   float64\n 28  humidity_lag4                2822 non-null   float64\n 29  humidity_lag5                2822 non-null   float64\ndtypes: float64(19), int64(11)\nmemory usage: 661.5 KB"
  },
  {
    "objectID": "modeling_python.html#pipeline---preprocessing",
    "href": "modeling_python.html#pipeline---preprocessing",
    "title": "6  Modeling - Python",
    "section": "6.3 Pipeline - Preprocessing",
    "text": "6.3 Pipeline - Preprocessing\n\nnum_columns = train_X.select_dtypes('number').columns\ncat_columns = train_X.select_dtypes('object').columns\n\nnum_pipe = Pipeline([(\"scaler\",StandardScaler())])\ncat_pipe = make_pipeline(\n  OneHotEncoder(handle_unknown=\"ignore\",sparse_output=False)\n)\n\npreprocess = ColumnTransformer(\n  [(\"num_process\",num_pipe,num_columns) ,\n  (\"cat_process\",cat_pipe,cat_columns)], remainder=\"passthrough\"\n)"
  },
  {
    "objectID": "modeling_python.html#pipeline---modeling",
    "href": "modeling_python.html#pipeline---modeling",
    "title": "6  Modeling - Python",
    "section": "6.4 Pipeline - Modeling",
    "text": "6.4 Pipeline - Modeling\n\ncv = KFold(n_splits=5,shuffle=False)\n\n\n6.4.1 Random Forest\n\npipe_rf = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",RandomForestClassifier())\n  ]\n)\n\nRandomForest_param = {'classifier__max_features': np.arange(0.5,1,0.1)}\n\nstart_time = time.time()\n\nRandomForest_search = GridSearchCV(estimator = pipe_rf,\n                      param_grid = RandomForest_param,\n                      cv = cv,\n                      scoring = \"roc_auc\")\n                      \nRandomForest_search.fit(train_X,train_y)\nprint(f\"{time.time()-start_time}s\")\nprint(f\"Random Forest Best Score: {RandomForest_search.best_score_}\")\n\npred = RandomForest_search.predict(test_X)\nprint(classification_report(test_y,pred))\n\n38.04331398010254s\nRandom Forest Best Score: 0.9230737753618434\n              precision    recall  f1-score   support\n\n           0       0.83      0.67      0.74       239\n           1       0.84      0.93      0.88       444\n\n    accuracy                           0.84       683\n   macro avg       0.83      0.80      0.81       683\nweighted avg       0.84      0.84      0.83       683\n\n\n\n\n\n6.4.2 Decision Tree\n\npipe_decisiontree = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",DecisionTreeClassifier())\n  ]\n)\n\ndecisiontree_param = {'classifier__ccp_alpha': np.arange(0.1,1,0.1)}\n\nstart_time = time.time()\n\ndecisiontree_search = GridSearchCV(estimator = pipe_decisiontree,\n                      param_grid = decisiontree_param,\n                      cv = cv,\n                      scoring = \"roc_auc\")\n                      \ndecisiontree_search.fit(train_X,train_y)\nprint(f\"{time.time()-start_time}s\")\nprint(f\"Decision Tree Best Score: {decisiontree_search.best_score_}\")\n\npred = decisiontree_search.predict(test_X)\nprint(classification_report(test_y,pred))\n\n2.4891738891601562s\nDecision Tree Best Score: 0.8524885734343242\n              precision    recall  f1-score   support\n\n           0       0.95      0.24      0.38       239\n           1       0.71      0.99      0.83       444\n\n    accuracy                           0.73       683\n   macro avg       0.83      0.62      0.60       683\nweighted avg       0.79      0.73      0.67       683\n\n\n\n\n\n6.4.3 Support Vector Machine\n\npipe_svc = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",SVC())\n  ]\n)\n\nSVC_param = {\"classifier__C\": np.arange(1,100,20)}\n\nstart_time = time.time()\n\nSVC_search = GridSearchCV(estimator = pipe_svc,\n                      param_grid = SVC_param,\n                      cv = cv,\n                      scoring = \"roc_auc\")\n                      \nSVC_search.fit(train_X,train_y)\nprint(f\"{time.time()-start_time}s\")\nprint(f\"SVM Classifier Best Score: {SVC_search.best_score_}\")\n\npred = SVC_search.predict(test_X)\nprint(classification_report(test_y,pred))\n\n4.321812868118286s\nSVM Classifier Best Score: 0.8571347816647856\n              precision    recall  f1-score   support\n\n           0       0.82      0.71      0.76       239\n           1       0.85      0.92      0.89       444\n\n    accuracy                           0.84       683\n   macro avg       0.84      0.81      0.82       683\nweighted avg       0.84      0.84      0.84       683\n\n\n\n\n\n6.4.4 XGBOOST\n\npipe_xgboost = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",XGBClassifier())\n  ]\n)\n\nXGBM_param = {\"classifier__learning_rate\": np.arange(0.5,1,0.1)}\n\nstart_time = time.time()\n\nXGBM_search = GridSearchCV(estimator = pipe_xgboost,\n                      param_grid = XGBM_param,\n                      cv = cv,\n                      scoring = \"roc_auc\")\n                      \nXGBM_search.fit(train_X,train_y)\nprint(f\"{time.time()-start_time}s\")\nprint(f\"XGBOOST Best Score: {XGBM_search.best_score_}\")\n\npred = XGBM_search.predict(test_X)\nprint(classification_report(test_y,pred))\n\n4.315324068069458s\nXGBOOST Best Score: 0.9336602959815906\n              precision    recall  f1-score   support\n\n           0       0.80      0.76      0.78       239\n           1       0.88      0.90      0.89       444\n\n    accuracy                           0.85       683\n   macro avg       0.84      0.83      0.83       683\nweighted avg       0.85      0.85      0.85       683\n\n\n\n\n\n6.4.5 Light GBM\nmessages가 많아 comments처리함\n\n#pipe_lgbm = Pipeline(\n#  [\n#    (\"preprocess\",preprocess),\n#    (\"classifier\",LGBMClassifier(force_col_wise=True))\n#  ]\n#)\n\n#LGBM_param = {\"classifier__learning_rate\": np.arange(0.5,1,0.1)}\n\n#start_time = time.time()\n\n#LGBM_search = GridSearchCV(estimator = pipe_lgbm,\n#                      param_grid = LGBM_param,\n#                      cv = cv,\n#                      scoring = \"roc_auc\")\n                      \n#LGBM_search.fit(train_X,train_y)\n#print(f\"{time.time()-start_time}s\")\n#print(f\"LGBM Best Score: {LGBM_search.best_score_}\")\n\n#pred = LGBM_search.predict(test_X)\n#print(classification_report(test_y,pred))\n\n\n\n6.4.6 Best Score / Best Parameter\n\nprint(f\"Random Forest Best Score: {RandomForest_search.best_score_}\")\nprint(f\"Random Forest Best Parameters: {RandomForest_search.best_params_}\")\nprint(f\"Decision Tree Best Score: {decisiontree_search.best_score_}\")\nprint(f\"Decision Tree Best Parameters: {decisiontree_search.best_params_}\")\nprint(f\"SVM Classifier Best Score: {SVC_search.best_score_}\")\nprint(f\"SVM Classifier Best Parameters: {SVC_search.best_params_}\")\nprint(f\"XGBOOST Best Score: {XGBM_search.best_score_}\")\nprint(f\"XGBOOST Best Parameters: {XGBM_search.best_params_}\")\n\nRandom Forest Best Score: 0.9230737753618434\nRandom Forest Best Parameters: {'classifier__max_features': 0.8999999999999999}\nDecision Tree Best Score: 0.8524885734343242\nDecision Tree Best Parameters: {'classifier__ccp_alpha': 0.1}\nSVM Classifier Best Score: 0.8571347816647856\nSVM Classifier Best Parameters: {'classifier__C': 1}\nXGBOOST Best Score: 0.9336602959815906\nXGBOOST Best Parameters: {'classifier__learning_rate': 0.7}"
  },
  {
    "objectID": "evaluation_python.html#evaluation---xgboost-모델",
    "href": "evaluation_python.html#evaluation---xgboost-모델",
    "title": "7  Tuning & Evaluation - Python",
    "section": "7.1 Evaluation - XGBOOST 모델",
    "text": "7.1 Evaluation - XGBOOST 모델\nCross Validation 기반하에 채택된 XGBOOST 모델을 평가해 본다."
  },
  {
    "objectID": "evaluation_python.html#library-loading",
    "href": "evaluation_python.html#library-loading",
    "title": "7  Tuning & Evaluation - Python",
    "section": "7.2 Library Loading",
    "text": "7.2 Library Loading\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport time\nfrom imblearn.over_sampling import SMOTE,RandomOverSampler\nimport matplotlib.pyplot as plt\nimport joblib\nimport warnings\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,KFold,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler,Normalizer,OneHotEncoder\nfrom sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,classification_report, roc_curve\nfrom sklearn import set_config\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier,plot_importance\nfrom lightgbm import LGBMClassifier\n#from catboost import CatBoostClassifier\nwarnings.filterwarnings(\"ignore\")"
  },
  {
    "objectID": "evaluation_python.html#data-loading",
    "href": "evaluation_python.html#data-loading",
    "title": "7  Tuning & Evaluation - Python",
    "section": "7.3 Data Loading",
    "text": "7.3 Data Loading\n\ntrain = pd.read_csv(\"train_1.csv\")\ntest = pd.read_csv(\"test_1.csv\")\n\ntrain = train.iloc[:,2:]\ntest = test.iloc[:,2:]\ntrain['fp2'] = np.where(train['fp2']==\"non_detection\",0,1)\ntest['fp2'] = np.where(test['fp2']==\"non_detection\",0,1)\ntrain[\"occupancy\"] = np.where(train[\"occupancy\"] == \"non_detection\",0,1)\ntest[\"occupancy\"]= np.where(test[\"occupancy\"] == \"non_detection\",0,1)\n\ntrain_X = train.drop(['occupancy',\"weekday\"],axis=1)\ntrain_y = train[['occupancy']]\nsmote = SMOTE(random_state=2023,k_neighbors=7)\ntrain_X,train_y = smote.fit_resample(train_X,train_y)\ntest_X = test.drop(['occupancy',\"weekday\"],axis=1)\ntest_y = test[['occupancy']]"
  },
  {
    "objectID": "evaluation_python.html#modeling---xgboost",
    "href": "evaluation_python.html#modeling---xgboost",
    "title": "7  Tuning & Evaluation - Python",
    "section": "7.4 Modeling - XGBOOST",
    "text": "7.4 Modeling - XGBOOST\n\n7.4.1 Pipeline - Preprocessing\n\nnum_columns = train_X.select_dtypes('number').columns\ncat_columns = train_X.select_dtypes('object').columns\n\nnum_pipe = Pipeline([(\"scaler\",StandardScaler())])\ncat_pipe = make_pipeline(\n  OneHotEncoder(handle_unknown=\"ignore\",sparse_output=False)\n)\n\npreprocess = ColumnTransformer(\n  [(\"num_process\",num_pipe,num_columns) ,\n  (\"cat_process\",cat_pipe,cat_columns)], remainder=\"passthrough\"\n)\n\n\n\n7.4.2 Pipeline - Cross Validation\n\ncv = KFold(n_splits=5,shuffle=False)\npipe_xgboost = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",XGBClassifier())\n  ]\n)\n\nXGBM_param = {\"classifier__learning_rate\": np.arange(0.5,1,0.1),\n              \"classifier__n_estimators\": np.arange(50,500,50) ,\n              \"classifier__max_depth\": np.arange(2,5,1)\n              }\n\nstart_time = time.time()\n\nXGBM_search = GridSearchCV(estimator = pipe_xgboost,\n                      param_grid = XGBM_param,\n                      cv = cv,\n                      scoring = \"roc_auc\")\n                      \nXGBM_search.fit(train_X,train_y)\nprint(\"\\n\")\nprint(f\"모델링 적합 시간: {time.time()-start_time}s\")\nprint(\"\\n\")\nprint(\"---------------------------------------------------------------------------\")\nprint(f\"XGBOOST Best Score: {XGBM_search.best_score_}\")\nprint(f\"XGBOOST Best Parameters: {XGBM_search.best_params_}\")\nprint(\"---------------------------------------------------------------------------\")\n\n\n\n모델링 적합 시간: 149.1704661846161s\n\n\n---------------------------------------------------------------------------\nXGBOOST Best Score: 0.9407269446876632\nXGBOOST Best Parameters: {'classifier__learning_rate': 0.6, 'classifier__max_depth': 2, 'classifier__n_estimators': 50}\n---------------------------------------------------------------------------\n\n\n\n\n7.4.3 Final Modeling\n\npipe_final = Pipeline(\n  [\n    (\"preprocess\",preprocess),\n    (\"classifier\",XGBClassifier(n_estimators = 50,\n                                learning_rate =  0.6,\n                                max_depth = 2))\n  ]\n)\n\npipe_final.fit(train_X,train_y)\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('num_process',\n                                                  Pipeline(steps=[('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['co2', 'temperature', 'humidity', 'door', 'motion', 'fp2', 'hour',\n       'discomfort_index', 'co2_rolling_std', 'temperature_rolling_std',\n       'humidity_rolling_std', 'motion_rolling_std', 'door_rolling_std',\n       'co2_tempe...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.6,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=2, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=50, n_jobs=None,\n                               num_parallel_tree=None, random_state=None, ...))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('preprocess',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('num_process',\n                                                  Pipeline(steps=[('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['co2', 'temperature', 'humidity', 'door', 'motion', 'fp2', 'hour',\n       'discomfort_index', 'co2_rolling_std', 'temperature_rolling_std',\n       'humidity_rolling_std', 'motion_rolling_std', 'door_rolling_std',\n       'co2_tempe...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.6,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=2, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=50, n_jobs=None,\n                               num_parallel_tree=None, random_state=None, ...))])preprocess: ColumnTransformerColumnTransformer(remainder='passthrough',\n                  transformers=[('num_process',\n                                 Pipeline(steps=[('scaler', StandardScaler())]),\n                                 Index(['co2', 'temperature', 'humidity', 'door', 'motion', 'fp2', 'hour',\n       'discomfort_index', 'co2_rolling_std', 'temperature_rolling_std',\n       'humidity_rolling_std', 'motion_rolling_std', 'door_rolling_std',\n       'co2_temperature_interaction', 'co2_humid...\n       'co2_lag2', 'co2_lag3', 'co2_lag4', 'co2_lag5', 'temperature_lag1',\n       'temperature_lag2', 'temperature_lag3', 'temperature_lag4',\n       'temperature_lag5', 'humidity_lag1', 'humidity_lag2', 'humidity_lag3',\n       'humidity_lag4', 'humidity_lag5'],\n      dtype='object')),\n                                ('cat_process',\n                                 Pipeline(steps=[('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 Index([], dtype='object'))])num_processIndex(['co2', 'temperature', 'humidity', 'door', 'motion', 'fp2', 'hour',\n       'discomfort_index', 'co2_rolling_std', 'temperature_rolling_std',\n       'humidity_rolling_std', 'motion_rolling_std', 'door_rolling_std',\n       'co2_temperature_interaction', 'co2_humidity_interaction', 'co2_lag1',\n       'co2_lag2', 'co2_lag3', 'co2_lag4', 'co2_lag5', 'temperature_lag1',\n       'temperature_lag2', 'temperature_lag3', 'temperature_lag4',\n       'temperature_lag5', 'humidity_lag1', 'humidity_lag2', 'humidity_lag3',\n       'humidity_lag4', 'humidity_lag5'],\n      dtype='object')StandardScalerStandardScaler()cat_processIndex([], dtype='object')OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)remainder[]passthroughpassthroughXGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.6, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=2, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=50, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)\n\n\n\n\n7.4.4 Evaluation with Final Model/Test Dataset\n\npred = pipe_final.predict(test_X)\npred_proba = pipe_final.predict_proba(test_X)[:,1]\nprint(\"\\n\")\nprint(\"----------------------------------------------------------\")\nprint(\"-------------------Major Metrics--------------------------\")\nprint(\"----------------------------------------------------------\")\nprint(classification_report(test_y,pred))\nprint(\"----------------------------------------------------------\")\nprint(\"\\n\")\n\n\n\n----------------------------------------------------------\n-------------------Major Metrics--------------------------\n----------------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.85      0.73      0.78       239\n           1       0.86      0.93      0.90       444\n\n    accuracy                           0.86       683\n   macro avg       0.86      0.83      0.84       683\nweighted avg       0.86      0.86      0.86       683\n\n----------------------------------------------------------\n\n\n\n\n\ndef roc_curve_plot(test_y, pred_proba):\n  fprs, tprs,thresholds = roc_curve(test_y,pred_proba)\n  plt.plot(fprs,tprs,label=\"ROC\")\n  plt.plot([0,1],'k--',label=\"Random\")\n  start,end = plt.xlim()\n  plt.xticks(np.round(np.arange(start,end,0.1),2))\n  plt.xlim(0,1);plt.ylim(0,1)\n  plt.xlabel('FPR(1-Specificity)'); plt.ylabel('TPR(Recal)')\n  plt.legend()\n  plt.show()\n\n\nprint(\"----------------------------------------------------------\")\nprint(\"---------------------ROC AUC Score------------------------\")\nprint(f\"--------------------{roc_auc_score(test_y,pred_proba)}--------------------\")\nprint(\"-----------------------ROC Curve--------------------------\")\nprint(\"----------------------------------------------------------\")\n\nroc_curve_plot(test_y,pred_proba)\n\n----------------------------------------------------------\n---------------------ROC AUC Score------------------------\n--------------------0.9191026800859438--------------------\n-----------------------ROC Curve--------------------------\n----------------------------------------------------------"
  }
]